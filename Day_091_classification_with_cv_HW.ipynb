{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    },
    "colab": {
      "name": "Day_091_classification_with_cv_HW.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tobeywang/2nd-ML100Days/blob/master/Day_091_classification_with_cv_HW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oq8UJegSEGB2",
        "colab_type": "text"
      },
      "source": [
        "## 作業目標\n",
        "* 嘗試比較用 color histogram 和 HOG 特徵來訓練的 SVM 分類器在 cifar10 training 和 testing data 上準確度的差別"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o39rRxklEGB3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "e8cad3dd-13e8-4dfb-8f99-e83d4023d32f"
      },
      "source": [
        "import os\n",
        "import keras\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\" # 使用 CPU\n",
        "\n",
        "import numpy as np\n",
        "import cv2 # 載入 cv2 套件\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "train, test = keras.datasets.cifar10.load_data()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNDzGPaIEGB6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, y_train = train\n",
        "x_test, y_test = test\n",
        "y_train = y_train.astype(int)\n",
        "y_test = y_test.astype(int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUJpKRFFEGB8",
        "colab_type": "text"
      },
      "source": [
        "#### 產生直方圖特徵的訓練資料"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s69WH_wtEGB9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train_histogram = []\n",
        "x_test_histogram = []\n",
        "\n",
        "# 對於所有訓練資料\n",
        "for i in range(len(x_train)):\n",
        "    chans = cv2.split(x_train[i]) # 把圖像的 3 個 channel 切分出來\n",
        "    # 對於所有 channel\n",
        "    hist_feature = []\n",
        "    for chan in chans:\n",
        "        # 計算該 channel 的直方圖\n",
        "        hist = cv2.calcHist([chan], [0], None, [16], [0, 256]) # 切成 16 個 bin\n",
        "        hist_feature.extend(hist.flatten())\n",
        "    # 把計算的直方圖特徵收集起來\n",
        "    x_train_histogram.append(hist_feature)\n",
        "\n",
        "# 對於所有測試資料也做一樣的處理\n",
        "for i in range(len(x_test)):\n",
        "    chans = cv2.split(x_test[i]) # 把圖像的 3 個 channel 切分出來\n",
        "    # 對於所有 channel\n",
        "    hist_feature = []\n",
        "    for chan in chans:\n",
        "        # 計算該 channel 的直方圖\n",
        "        hist = cv2.calcHist([chan], [0], None, [16], [0, 256]) # 切成 16 個 bin\n",
        "        hist_feature.extend(hist.flatten())\n",
        "    x_test_histogram.append(hist_feature)\n",
        "\n",
        "x_train_histogram = np.array(x_train_histogram)\n",
        "x_test_histogram = np.array(x_test_histogram)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V97r29VIEGB_",
        "colab_type": "text"
      },
      "source": [
        "#### 產生 HOG 特徵的訓練資料\n",
        "* HOG 特徵通過計算和統計圖像局部區域的梯度方向直方圖來構建特徵，具體細節不在我們涵蓋的範圍裡面，有興趣的同學請參考[補充資料](https://www.cnblogs.com/zyly/p/9651261.html)哦"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHbISmzuEGCA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# SZ=20\n",
        "bin_n = 16 # Number of bins\n",
        "\n",
        "def hog(img):\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "    gx = cv2.Sobel(img, cv2.CV_32F, 1, 0)\n",
        "    gy = cv2.Sobel(img, cv2.CV_32F, 0, 1)\n",
        "    mag, ang = cv2.cartToPolar(gx, gy)\n",
        "    bins = np.int32(bin_n*ang/(2*np.pi))    # quantizing binvalues in (0...16)\n",
        "    bin_cells = bins[:10,:10], bins[10:,:10], bins[:10,10:], bins[10:,10:]\n",
        "    mag_cells = mag[:10,:10], mag[10:,:10], mag[:10,10:], mag[10:,10:]\n",
        "    hists = [np.bincount(b.ravel(), m.ravel(), bin_n) for b, m in zip(bin_cells, mag_cells)]\n",
        "    hist = np.hstack(hists)     # hist is a 64 bit vector\n",
        "    return hist.astype(np.float32)\n",
        "\n",
        "x_train_hog = np.array([hog(x) for x in x_train])\n",
        "x_test_hog = np.array([hog(x) for x in x_test])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gybuA7Y7EGCC",
        "colab_type": "text"
      },
      "source": [
        "#### SVM model\n",
        "* SVM 是機器學習中一個經典的分類算法，具體細節有興趣可以參考 [該知乎上的解釋](https://www.zhihu.com/question/21094489)，我們這裡直接調用 opencv 中實現好的函數"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ETOOt6XEGCC",
        "colab_type": "text"
      },
      "source": [
        "#### 用 histogram 特徵訓練 SVM 模型\n",
        "* 訓練過程可能會花點時間，請等他一下"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TpsQvVyEGCD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SVM_hist = cv2.ml.SVM_create()\n",
        "SVM_hist.setKernel(cv2.ml.SVM_LINEAR)\n",
        "SVM_hist.setGamma(5.383)\n",
        "SVM_hist.setType(cv2.ml.SVM_C_SVC)\n",
        "SVM_hist.setC(2.67)\n",
        "\n",
        "#training\n",
        "SVM_hist.train(x_train_histogram, cv2.ml.ROW_SAMPLE, y_train)\n",
        "\n",
        "# prediction\n",
        "_, y_hist_train = SVM_hist.predict(x_train_histogram)\n",
        "_, y_hist_test = SVM_hist.predict(x_test_histogram)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtxkXgOLEGCF",
        "colab_type": "text"
      },
      "source": [
        "#### 用 HOG 特徵訓練 SVM 模型\n",
        "* 訓練過程可能會花點時間，請等他一下"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiXStEbIEGCG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SVM_hog = cv2.ml.SVM_create()\n",
        "SVM_hog.setKernel(cv2.ml.SVM_LINEAR)\n",
        "SVM_hog.setGamma(5.383)\n",
        "SVM_hog.setType(cv2.ml.SVM_C_SVC)\n",
        "SVM_hog.setC(2.67)\n",
        "\n",
        "#training\n",
        "SVM_hog.train(x_train_hog, cv2.ml.ROW_SAMPLE, y_train)\n",
        "\n",
        "# prediction\n",
        "_, y_hog_train = SVM_hog.predict(x_train_hog)\n",
        "_, y_hog_test = SVM_hog.predict(x_test_hog)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "boHw_JLsF1b_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "b9e5ef23-f5df-4769-e6c3-819d053b4014"
      },
      "source": [
        "print(\"HOG-------\")\n",
        "print(\"train_Acc :\",np.sum(y_train==y_hog_train)/len(y_train))\n",
        "print(\"test_Acc :\",np.sum(y_test == y_hog_test)/len(y_test))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "HOG-------\n",
            "train_Acc : 0.23624\n",
            "test_Acc : 0.2318\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6IUe-4MGCwK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "66858caa-86c3-4f0b-eecd-c43a81cbd4b7"
      },
      "source": [
        "print(\"histogram-------\")\n",
        "print(\"train_Acc :\",np.sum(y_train==y_hist_train)/len(y_train))\n",
        "print(\"test_Acc :\",np.sum(y_test == y_hist_test)/len(y_test))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "histogram-------\n",
            "train_Acc : 0.12078\n",
            "test_Acc : 0.1228\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}