{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "Day_078_HW.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tobeywang/2nd-ML100Days/blob/master/Day_078_HW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kzk_XweItLVy",
        "colab_type": "text"
      },
      "source": [
        "## Work\n",
        "1. 請嘗試將 preproc_x 替換成以每筆資料的 min/max 進行標準化至 -1 ~ 1 間，再進行訓練\n",
        "2. 請嘗試將 mlp 疊更深 (e.g 5~10 層)，進行訓練後觀察 learning curve 的走勢\n",
        "3. (optional) 請改用 GPU 進行訓練 (如果你有 GPU 的話)，比較使用 CPU 與 GPU 的訓練速度"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1_jda69tLVz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## \n",
        "\"\"\"\n",
        "Your code here (optional)\n",
        "確認硬體資源\n",
        "\"\"\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tomO6o-ltLV1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "36887b19-18f8-4429-acbe-89045bc9bb45"
      },
      "source": [
        "import os\n",
        "import keras\n",
        "\n",
        "# 請嘗試設定 GPU：os.environ\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpidtijbtLV4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "aa34bf7a-70a5-4982-ab8d-ade461a558f5"
      },
      "source": [
        "train, test = keras.datasets.cifar10.load_data()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 9s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNUiCy-jtLV6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## 資料前處理\n",
        "\"\"\"\n",
        "Your code here\n",
        "\"\"\"\n",
        "def preproc_x(x, flatten=True):\n",
        "    x = 2*(x / 255)-1.\n",
        "    if flatten:\n",
        "        x = x.reshape((len(x), -1))\n",
        "    return x\n",
        "\n",
        "def preproc_y(y,num_classes=10):\n",
        "    if y.shape[-1] == 1:\n",
        "        y = keras.utils.to_categorical(y, num_classes)\n",
        "    return y   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3aKOLE4QtLV8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, y_train = train\n",
        "x_test, y_test = test\n",
        "\n",
        "# Preproc the inputs\n",
        "x_train = preproc_x(x_train)\n",
        "x_test = preproc_x(x_test)\n",
        "\n",
        "# Preprc the outputs\n",
        "y_train = preproc_y(y_train)\n",
        "y_test = preproc_y(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99wX8nET0lWu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "744968cc-dab9-4436-e967-3ce05975bad5"
      },
      "source": [
        "x_train"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.5372549 , -0.51372549, -0.50588235, ..., -0.03529412,\n",
              "        -0.27843137, -0.43529412],\n",
              "       [ 0.20784314,  0.38823529,  0.46666667, ...,  0.12156863,\n",
              "         0.04313725,  0.12941176],\n",
              "       [ 1.        ,  1.        ,  1.        , ..., -0.37254902,\n",
              "        -0.3254902 , -0.34117647],\n",
              "       ...,\n",
              "       [-0.7254902 ,  0.39607843,  0.84313725, ..., -0.90588235,\n",
              "        -0.75686275, -0.60784314],\n",
              "       [ 0.48235294,  0.65490196,  0.88235294, ...,  0.52941176,\n",
              "         0.49019608,  0.34117647],\n",
              "       [ 0.79607843,  0.79607843,  0.8745098 , ...,  0.27843137,\n",
              "         0.27843137,  0.2627451 ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdApwK_NtLV9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "478359be-efbd-49f7-d078-e9ee0303b372"
      },
      "source": [
        "\"\"\"Code Here\n",
        "建立你的神經網路\n",
        "\"\"\"\n",
        "def build_mlp(input_shape, output_units=10, num_neurons=[512, 256, 128,64,8]):\n",
        "    input_layer = keras.layers.Input(input_shape)\n",
        "    \n",
        "    for i, n_units in enumerate(num_neurons):\n",
        "        if i == 0:\n",
        "            x = keras.layers.Dense(units=n_units, activation=\"relu\", name=\"hidden_layer\"+str(i+1))(input_layer)\n",
        "        else:\n",
        "            x = keras.layers.Dense(units=n_units, activation=\"relu\", name=\"hidden_layer\"+str(i+1))(x)\n",
        "    \n",
        "    out = keras.layers.Dense(units=output_units, activation=\"softmax\", name=\"output\")(x)\n",
        "    \n",
        "    model = keras.models.Model(inputs=[input_layer], outputs=[out])\n",
        "    return model\n",
        "model = build_mlp(input_shape=x_train.shape[1:])\n",
        "model.summary()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         (None, 3072)              0         \n",
            "_________________________________________________________________\n",
            "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
            "_________________________________________________________________\n",
            "hidden_layer2 (Dense)        (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "hidden_layer3 (Dense)        (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "hidden_layer4 (Dense)        (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "hidden_layer5 (Dense)        (None, 8)                 520       \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                90        \n",
            "=================================================================\n",
            "Total params: 1,746,466\n",
            "Trainable params: 1,746,466\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydZ2eufItLV_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## 超參數設定\n",
        "LEARNING_RATE = 0.001\n",
        "EPOCHS = 100\n",
        "BATCH_SIZE = 256"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wg542h8ktLWB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "0b9add8f-7a41-443e-a1ae-dd01a8e68c6b"
      },
      "source": [
        "optimizer = keras.optimizers.Adam(lr=LEARNING_RATE)\n",
        "model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=optimizer)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0812 03:21:07.895510 140350816900992 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0812 03:21:07.908493 140350816900992 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnLGGL7AtLWD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "dba90890-cbd6-42dc-e671-f3bc3b72ab0d"
      },
      "source": [
        "model.fit(x_train, y_train, \n",
        "          epochs=EPOCHS, \n",
        "          batch_size=BATCH_SIZE, \n",
        "          validation_data=(x_test, y_test), \n",
        "          shuffle=True)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0812 03:21:10.028542 140350816900992 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0812 03:21:10.107053 140350816900992 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/100\n",
            "50000/50000 [==============================] - 6s 118us/step - loss: 2.0311 - acc: 0.2685 - val_loss: 1.8606 - val_acc: 0.3747\n",
            "Epoch 2/100\n",
            "50000/50000 [==============================] - 2s 43us/step - loss: 1.7632 - acc: 0.3976 - val_loss: 1.6497 - val_acc: 0.4166\n",
            "Epoch 3/100\n",
            "50000/50000 [==============================] - 2s 43us/step - loss: 1.5553 - acc: 0.4570 - val_loss: 1.5161 - val_acc: 0.4708\n",
            "Epoch 4/100\n",
            "50000/50000 [==============================] - 2s 42us/step - loss: 1.4104 - acc: 0.5055 - val_loss: 1.4435 - val_acc: 0.4996\n",
            "Epoch 5/100\n",
            "50000/50000 [==============================] - 2s 43us/step - loss: 1.3073 - acc: 0.5418 - val_loss: 1.4108 - val_acc: 0.5074\n",
            "Epoch 6/100\n",
            "50000/50000 [==============================] - 2s 43us/step - loss: 1.2200 - acc: 0.5699 - val_loss: 1.3888 - val_acc: 0.5204\n",
            "Epoch 7/100\n",
            "50000/50000 [==============================] - 2s 43us/step - loss: 1.1413 - acc: 0.5987 - val_loss: 1.3839 - val_acc: 0.5261\n",
            "Epoch 8/100\n",
            "50000/50000 [==============================] - 2s 43us/step - loss: 1.0655 - acc: 0.6217 - val_loss: 1.3861 - val_acc: 0.5324\n",
            "Epoch 9/100\n",
            "50000/50000 [==============================] - 2s 42us/step - loss: 0.9900 - acc: 0.6518 - val_loss: 1.4013 - val_acc: 0.5364\n",
            "Epoch 10/100\n",
            "50000/50000 [==============================] - 2s 43us/step - loss: 0.9217 - acc: 0.6741 - val_loss: 1.4501 - val_acc: 0.5300\n",
            "Epoch 11/100\n",
            "50000/50000 [==============================] - 2s 43us/step - loss: 0.8499 - acc: 0.7009 - val_loss: 1.4891 - val_acc: 0.5241\n",
            "Epoch 12/100\n",
            "50000/50000 [==============================] - 2s 43us/step - loss: 0.7896 - acc: 0.7195 - val_loss: 1.5075 - val_acc: 0.5304\n",
            "Epoch 13/100\n",
            "50000/50000 [==============================] - 2s 42us/step - loss: 0.7297 - acc: 0.7405 - val_loss: 1.5995 - val_acc: 0.5309\n",
            "Epoch 14/100\n",
            "50000/50000 [==============================] - 2s 43us/step - loss: 0.6643 - acc: 0.7643 - val_loss: 1.6909 - val_acc: 0.5168\n",
            "Epoch 15/100\n",
            "50000/50000 [==============================] - 2s 42us/step - loss: 0.6146 - acc: 0.7819 - val_loss: 1.7776 - val_acc: 0.5271\n",
            "Epoch 16/100\n",
            "50000/50000 [==============================] - 2s 42us/step - loss: 0.5624 - acc: 0.8017 - val_loss: 1.8070 - val_acc: 0.5302\n",
            "Epoch 17/100\n",
            "50000/50000 [==============================] - 2s 42us/step - loss: 0.5118 - acc: 0.8182 - val_loss: 1.9081 - val_acc: 0.5322\n",
            "Epoch 18/100\n",
            "50000/50000 [==============================] - 2s 42us/step - loss: 0.4651 - acc: 0.8367 - val_loss: 1.9662 - val_acc: 0.5272\n",
            "Epoch 19/100\n",
            "50000/50000 [==============================] - 2s 42us/step - loss: 0.4408 - acc: 0.8438 - val_loss: 2.0556 - val_acc: 0.5246\n",
            "Epoch 20/100\n",
            "50000/50000 [==============================] - 2s 42us/step - loss: 0.4203 - acc: 0.8524 - val_loss: 2.1113 - val_acc: 0.5262\n",
            "Epoch 21/100\n",
            "50000/50000 [==============================] - 2s 42us/step - loss: 0.3616 - acc: 0.8728 - val_loss: 2.2382 - val_acc: 0.5310\n",
            "Epoch 22/100\n",
            "50000/50000 [==============================] - 2s 40us/step - loss: 0.3487 - acc: 0.8787 - val_loss: 2.4186 - val_acc: 0.5270\n",
            "Epoch 23/100\n",
            "50000/50000 [==============================] - 2s 40us/step - loss: 0.3248 - acc: 0.8867 - val_loss: 2.4186 - val_acc: 0.5251\n",
            "Epoch 24/100\n",
            "50000/50000 [==============================] - 2s 40us/step - loss: 0.2987 - acc: 0.8969 - val_loss: 2.5552 - val_acc: 0.5272\n",
            "Epoch 25/100\n",
            "50000/50000 [==============================] - 2s 45us/step - loss: 0.2791 - acc: 0.9026 - val_loss: 2.5996 - val_acc: 0.5256\n",
            "Epoch 26/100\n",
            "50000/50000 [==============================] - 2s 45us/step - loss: 0.2698 - acc: 0.9064 - val_loss: 2.6598 - val_acc: 0.5196\n",
            "Epoch 27/100\n",
            "50000/50000 [==============================] - 2s 45us/step - loss: 0.2437 - acc: 0.9146 - val_loss: 2.8248 - val_acc: 0.5156\n",
            "Epoch 28/100\n",
            "50000/50000 [==============================] - 2s 45us/step - loss: 0.2536 - acc: 0.9114 - val_loss: 2.8369 - val_acc: 0.5212\n",
            "Epoch 29/100\n",
            "50000/50000 [==============================] - 2s 45us/step - loss: 0.2455 - acc: 0.9147 - val_loss: 2.8580 - val_acc: 0.5231\n",
            "Epoch 30/100\n",
            "50000/50000 [==============================] - 2s 45us/step - loss: 0.2079 - acc: 0.9292 - val_loss: 2.9156 - val_acc: 0.5251\n",
            "Epoch 31/100\n",
            "50000/50000 [==============================] - 2s 45us/step - loss: 0.1996 - acc: 0.9308 - val_loss: 2.9851 - val_acc: 0.5243\n",
            "Epoch 32/100\n",
            "50000/50000 [==============================] - 2s 46us/step - loss: 0.1938 - acc: 0.9337 - val_loss: 3.1087 - val_acc: 0.5232\n",
            "Epoch 33/100\n",
            "50000/50000 [==============================] - 2s 45us/step - loss: 0.1956 - acc: 0.9320 - val_loss: 3.1381 - val_acc: 0.5163\n",
            "Epoch 34/100\n",
            "50000/50000 [==============================] - 2s 45us/step - loss: 0.1977 - acc: 0.9327 - val_loss: 3.1799 - val_acc: 0.5224\n",
            "Epoch 35/100\n",
            "50000/50000 [==============================] - 2s 44us/step - loss: 0.1799 - acc: 0.9390 - val_loss: 3.2419 - val_acc: 0.5129\n",
            "Epoch 36/100\n",
            "50000/50000 [==============================] - 2s 45us/step - loss: 0.1630 - acc: 0.9451 - val_loss: 3.3002 - val_acc: 0.5208\n",
            "Epoch 37/100\n",
            "50000/50000 [==============================] - 2s 45us/step - loss: 0.1510 - acc: 0.9484 - val_loss: 3.2161 - val_acc: 0.5178\n",
            "Epoch 38/100\n",
            "50000/50000 [==============================] - 2s 42us/step - loss: 0.1630 - acc: 0.9438 - val_loss: 3.2461 - val_acc: 0.5241\n",
            "Epoch 39/100\n",
            "50000/50000 [==============================] - 2s 40us/step - loss: 0.1662 - acc: 0.9435 - val_loss: 3.2991 - val_acc: 0.5232\n",
            "Epoch 40/100\n",
            "50000/50000 [==============================] - 2s 40us/step - loss: 0.1553 - acc: 0.9462 - val_loss: 3.2818 - val_acc: 0.5281\n",
            "Epoch 41/100\n",
            "50000/50000 [==============================] - 2s 39us/step - loss: 0.1516 - acc: 0.9472 - val_loss: 3.2731 - val_acc: 0.5209\n",
            "Epoch 42/100\n",
            "50000/50000 [==============================] - 2s 39us/step - loss: 0.1310 - acc: 0.9554 - val_loss: 3.4227 - val_acc: 0.5201\n",
            "Epoch 43/100\n",
            "50000/50000 [==============================] - 2s 39us/step - loss: 0.1312 - acc: 0.9570 - val_loss: 3.4846 - val_acc: 0.5235\n",
            "Epoch 44/100\n",
            "50000/50000 [==============================] - 2s 39us/step - loss: 0.1463 - acc: 0.9506 - val_loss: 3.3981 - val_acc: 0.5238\n",
            "Epoch 45/100\n",
            "50000/50000 [==============================] - 2s 39us/step - loss: 0.1444 - acc: 0.9504 - val_loss: 3.4875 - val_acc: 0.5201\n",
            "Epoch 46/100\n",
            "50000/50000 [==============================] - 2s 39us/step - loss: 0.1202 - acc: 0.9596 - val_loss: 3.5383 - val_acc: 0.5236\n",
            "Epoch 47/100\n",
            "50000/50000 [==============================] - 2s 39us/step - loss: 0.1318 - acc: 0.9569 - val_loss: 3.5470 - val_acc: 0.5211\n",
            "Epoch 48/100\n",
            "50000/50000 [==============================] - 2s 39us/step - loss: 0.1367 - acc: 0.9550 - val_loss: 3.5549 - val_acc: 0.5168\n",
            "Epoch 49/100\n",
            "50000/50000 [==============================] - 2s 39us/step - loss: 0.1276 - acc: 0.9565 - val_loss: 3.4809 - val_acc: 0.5279\n",
            "Epoch 50/100\n",
            "50000/50000 [==============================] - 2s 39us/step - loss: 0.1172 - acc: 0.9607 - val_loss: 3.6040 - val_acc: 0.5289\n",
            "Epoch 51/100\n",
            "50000/50000 [==============================] - 2s 40us/step - loss: 0.1165 - acc: 0.9613 - val_loss: 3.5517 - val_acc: 0.5290\n",
            "Epoch 52/100\n",
            "50000/50000 [==============================] - 2s 39us/step - loss: 0.1183 - acc: 0.9609 - val_loss: 3.6975 - val_acc: 0.5268\n",
            "Epoch 53/100\n",
            "50000/50000 [==============================] - 2s 39us/step - loss: 0.1086 - acc: 0.9643 - val_loss: 3.6753 - val_acc: 0.5244\n",
            "Epoch 54/100\n",
            "50000/50000 [==============================] - 2s 39us/step - loss: 0.1093 - acc: 0.9638 - val_loss: 3.7138 - val_acc: 0.5224\n",
            "Epoch 55/100\n",
            "50000/50000 [==============================] - 2s 40us/step - loss: 0.1195 - acc: 0.9595 - val_loss: 3.6529 - val_acc: 0.5183\n",
            "Epoch 56/100\n",
            "50000/50000 [==============================] - 2s 39us/step - loss: 0.1269 - acc: 0.9583 - val_loss: 3.7216 - val_acc: 0.5272\n",
            "Epoch 57/100\n",
            "50000/50000 [==============================] - 2s 39us/step - loss: 0.1095 - acc: 0.9637 - val_loss: 3.7358 - val_acc: 0.5282\n",
            "Epoch 58/100\n",
            "50000/50000 [==============================] - 2s 39us/step - loss: 0.0943 - acc: 0.9693 - val_loss: 3.7672 - val_acc: 0.5273\n",
            "Epoch 59/100\n",
            "50000/50000 [==============================] - 2s 39us/step - loss: 0.0881 - acc: 0.9709 - val_loss: 3.8631 - val_acc: 0.5230\n",
            "Epoch 60/100\n",
            "50000/50000 [==============================] - 2s 39us/step - loss: 0.1114 - acc: 0.9634 - val_loss: 3.7271 - val_acc: 0.5205\n",
            "Epoch 61/100\n",
            "50000/50000 [==============================] - 2s 39us/step - loss: 0.1077 - acc: 0.9635 - val_loss: 3.8339 - val_acc: 0.5172\n",
            "Epoch 62/100\n",
            "50000/50000 [==============================] - 2s 39us/step - loss: 0.0898 - acc: 0.9699 - val_loss: 3.8385 - val_acc: 0.5282\n",
            "Epoch 63/100\n",
            "50000/50000 [==============================] - 2s 39us/step - loss: 0.0764 - acc: 0.9747 - val_loss: 3.8614 - val_acc: 0.5300\n",
            "Epoch 64/100\n",
            "50000/50000 [==============================] - 2s 39us/step - loss: 0.1051 - acc: 0.9664 - val_loss: 3.8886 - val_acc: 0.5268\n",
            "Epoch 65/100\n",
            "50000/50000 [==============================] - 2s 39us/step - loss: 0.1053 - acc: 0.9652 - val_loss: 3.6657 - val_acc: 0.5284\n",
            "Epoch 66/100\n",
            "50000/50000 [==============================] - 2s 39us/step - loss: 0.0871 - acc: 0.9714 - val_loss: 3.8907 - val_acc: 0.5226\n",
            "Epoch 67/100\n",
            "50000/50000 [==============================] - 2s 39us/step - loss: 0.0949 - acc: 0.9688 - val_loss: 3.7929 - val_acc: 0.5243\n",
            "Epoch 68/100\n",
            "50000/50000 [==============================] - 2s 39us/step - loss: 0.0996 - acc: 0.9678 - val_loss: 3.9210 - val_acc: 0.5211\n",
            "Epoch 69/100\n",
            "50000/50000 [==============================] - 2s 42us/step - loss: 0.1031 - acc: 0.9670 - val_loss: 3.7689 - val_acc: 0.5181\n",
            "Epoch 70/100\n",
            "50000/50000 [==============================] - 2s 44us/step - loss: 0.0837 - acc: 0.9724 - val_loss: 3.8713 - val_acc: 0.5319\n",
            "Epoch 71/100\n",
            "50000/50000 [==============================] - 2s 45us/step - loss: 0.0763 - acc: 0.9749 - val_loss: 3.9165 - val_acc: 0.5229\n",
            "Epoch 72/100\n",
            "50000/50000 [==============================] - 2s 45us/step - loss: 0.0774 - acc: 0.9747 - val_loss: 4.0206 - val_acc: 0.5229\n",
            "Epoch 73/100\n",
            "50000/50000 [==============================] - 2s 46us/step - loss: 0.1065 - acc: 0.9663 - val_loss: 3.8736 - val_acc: 0.5194\n",
            "Epoch 74/100\n",
            "50000/50000 [==============================] - 2s 46us/step - loss: 0.0711 - acc: 0.9766 - val_loss: 4.0070 - val_acc: 0.5179\n",
            "Epoch 75/100\n",
            "50000/50000 [==============================] - 2s 46us/step - loss: 0.0777 - acc: 0.9746 - val_loss: 4.0016 - val_acc: 0.5238\n",
            "Epoch 76/100\n",
            "50000/50000 [==============================] - 2s 46us/step - loss: 0.0800 - acc: 0.9741 - val_loss: 3.9941 - val_acc: 0.5231\n",
            "Epoch 77/100\n",
            "50000/50000 [==============================] - 2s 46us/step - loss: 0.0806 - acc: 0.9741 - val_loss: 4.0608 - val_acc: 0.5241\n",
            "Epoch 78/100\n",
            "50000/50000 [==============================] - 2s 45us/step - loss: 0.0903 - acc: 0.9715 - val_loss: 3.9565 - val_acc: 0.5183\n",
            "Epoch 79/100\n",
            "50000/50000 [==============================] - 2s 44us/step - loss: 0.0856 - acc: 0.9720 - val_loss: 3.9857 - val_acc: 0.5200\n",
            "Epoch 80/100\n",
            "50000/50000 [==============================] - 2s 44us/step - loss: 0.0819 - acc: 0.9732 - val_loss: 4.0122 - val_acc: 0.5276\n",
            "Epoch 81/100\n",
            "50000/50000 [==============================] - 2s 44us/step - loss: 0.0709 - acc: 0.9767 - val_loss: 3.9869 - val_acc: 0.5276\n",
            "Epoch 82/100\n",
            "50000/50000 [==============================] - 2s 43us/step - loss: 0.0663 - acc: 0.9787 - val_loss: 4.0660 - val_acc: 0.5197\n",
            "Epoch 83/100\n",
            "50000/50000 [==============================] - 2s 41us/step - loss: 0.0703 - acc: 0.9779 - val_loss: 4.0882 - val_acc: 0.5303\n",
            "Epoch 84/100\n",
            "50000/50000 [==============================] - 2s 40us/step - loss: 0.0808 - acc: 0.9748 - val_loss: 4.0572 - val_acc: 0.5213\n",
            "Epoch 85/100\n",
            "50000/50000 [==============================] - 2s 39us/step - loss: 0.0837 - acc: 0.9730 - val_loss: 4.0520 - val_acc: 0.5187\n",
            "Epoch 86/100\n",
            "50000/50000 [==============================] - 2s 40us/step - loss: 0.0823 - acc: 0.9726 - val_loss: 4.1083 - val_acc: 0.5165\n",
            "Epoch 87/100\n",
            "50000/50000 [==============================] - 2s 40us/step - loss: 0.0876 - acc: 0.9722 - val_loss: 4.0007 - val_acc: 0.5236\n",
            "Epoch 88/100\n",
            "50000/50000 [==============================] - 2s 40us/step - loss: 0.0658 - acc: 0.9792 - val_loss: 4.0496 - val_acc: 0.5206\n",
            "Epoch 89/100\n",
            "50000/50000 [==============================] - 2s 39us/step - loss: 0.0494 - acc: 0.9840 - val_loss: 4.1772 - val_acc: 0.5287\n",
            "Epoch 90/100\n",
            "50000/50000 [==============================] - 2s 39us/step - loss: 0.0710 - acc: 0.9771 - val_loss: 4.1204 - val_acc: 0.5131\n",
            "Epoch 91/100\n",
            "50000/50000 [==============================] - 2s 40us/step - loss: 0.0813 - acc: 0.9735 - val_loss: 4.1047 - val_acc: 0.5155\n",
            "Epoch 92/100\n",
            "50000/50000 [==============================] - 2s 40us/step - loss: 0.0994 - acc: 0.9692 - val_loss: 4.0121 - val_acc: 0.5221\n",
            "Epoch 93/100\n",
            "50000/50000 [==============================] - 2s 39us/step - loss: 0.0584 - acc: 0.9806 - val_loss: 4.1584 - val_acc: 0.5275\n",
            "Epoch 94/100\n",
            "50000/50000 [==============================] - 2s 39us/step - loss: 0.0502 - acc: 0.9835 - val_loss: 4.1283 - val_acc: 0.5252\n",
            "Epoch 95/100\n",
            "50000/50000 [==============================] - 2s 39us/step - loss: 0.0666 - acc: 0.9788 - val_loss: 4.0881 - val_acc: 0.5089\n",
            "Epoch 96/100\n",
            "50000/50000 [==============================] - 2s 39us/step - loss: 0.0690 - acc: 0.9779 - val_loss: 4.1435 - val_acc: 0.5225\n",
            "Epoch 97/100\n",
            "50000/50000 [==============================] - 2s 39us/step - loss: 0.0799 - acc: 0.9756 - val_loss: 4.1844 - val_acc: 0.5184\n",
            "Epoch 98/100\n",
            "50000/50000 [==============================] - 2s 39us/step - loss: 0.0644 - acc: 0.9797 - val_loss: 4.1504 - val_acc: 0.5230\n",
            "Epoch 99/100\n",
            "50000/50000 [==============================] - 2s 39us/step - loss: 0.0428 - acc: 0.9863 - val_loss: 4.2091 - val_acc: 0.5236\n",
            "Epoch 100/100\n",
            "50000/50000 [==============================] - 2s 40us/step - loss: 0.0886 - acc: 0.9723 - val_loss: 4.0785 - val_acc: 0.5168\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa5ad70e208>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HD7SPjh2tLWF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "train_loss = model.history.history[\"loss\"]\n",
        "valid_loss = model.history.history[\"val_loss\"]\n",
        "\n",
        "train_acc = model.history.history[\"acc\"]\n",
        "valid_acc = model.history.history[\"val_acc\"]\n",
        "\n",
        "plt.plot(range(len(train_loss)), train_loss, label=\"train loss\")\n",
        "plt.plot(range(len(valid_loss)), valid_loss, label=\"valid loss\")\n",
        "plt.legend()\n",
        "plt.title(\"Loss\")\n",
        "plt.show()\n",
        "\n",
        "plt.plot(range(len(train_acc)), train_acc, label=\"train accuracy\")\n",
        "plt.plot(range(len(valid_acc)), valid_acc, label=\"valid accuracy\")\n",
        "plt.legend()\n",
        "plt.title(\"Accuracy\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}